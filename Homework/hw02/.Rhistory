clear
noHigh = 0
hasHigh = function(vec) {
for (j in length(vec)) {
if (vec[j] >= 10) {
return(TRUE)
}
}
return(FALSE)
}
for (i in 1:M) {
cards = sample(deck, 5, replace = FALSE)
if (hasHigh(cards) == FALSE) {
noHigh = noHigh + 1
}
}
noHigh
cards
deck
noHigh = 0
hasHigh = function(vec) {
for (j in length(vec)) {
if (vec[j] >= 10) {
return(TRUE)
}
}
return(FALSE)
}
for (i in 1:M) {
cards = sample(deck, 5, replace = FALSE)
if (hasHigh(cards) == FALSE) {
noHigh = noHigh + 1
}
}
noHigh
noHigh = 0
hasHigh = function(vec) {
for (j in length(vec)) {
if (vec[j] >= 10) {
return(TRUE)
}
}
return(FALSE)
}
for (i in 1:M) {
cards = sample(deck, 5, replace = FALSE)
if (hasHigh(cards) == FALSE) {
noHigh = noHigh + 1
}
}
noHigh
prob = noHigh / M
prob
cards
cards = sample(deck, 5, replace = FALSE)
cards
cards = sample(deck, 5, replace = FALSE)
cards
cards = sample(deck, 5, replace = FALSE)
cards
cards = sample(deck, 5, replace = FALSE)
cards
cards = sample(deck, 5, replace = FALSE)
cards
hasHigh(cards)
cards = sample(deck, 5, replace = FALSE)
cards
hasHigh(cards)
cards
hasHigh(cards)
cards[1]
cards[1] >= 10
hasHigh = function(vec) {
for (j in 1:length(vec)) {
if (vec[j] >= 10) {
return(TRUE)
}
}
return(FALSE)
}
hasHigh(cards)
?table
cards
table(cards)
testT = table(cards)
sum(testT == 2)
sum(testT == 1)
M
before = c(4,5,6,3,6,3,4,5,5,3,4,6,4,6,3,4,2,2,0,7,5,8,4,5,1,4,4,8,2,3)
after  = c(3,2,4,3,7,5,5,2,2,4,5,2,2,6,1,5,6,3,2,3,7,3,4,5,4,2,2,6,7,8)
xbar_before = mean(before)
xbar_after = mean(after)
xbar_after - xbar_before
xbar_before = mean(before)
xbar_after = mean(after)
c(xbar_before, xbar_after)
# Code from class
permute_and_compute = function( ctrl_data, trmt_data ) {
# Pool the data
pooled_data <- c( ctrl_data, trmt_data );
# Randomly shuffle the data and assign it to control and treatment groups.
n_ctrl <- length( ctrl_data );
n_trmt <- length( trmt_data );
n_total <- n_ctrl + n_trmt;
shuffled_data <- sample( pooled_data, size=n_total, replace=FALSE );
# Now, the first n_ctrl of these data points are our new control group
# and the remaining elements are assigned to our treatment group.
shuffled_ctrl <- shuffled_data[1:n_ctrl];
shuffled_trmt <- shuffled_data[(n_ctrl+1):n_total];
# Okay, last step: compute the difference in means of our two samples.
return( mean(shuffled_trmt)-mean(shuffled_ctrl) );
}
# Monte Carlo
NMC <- 1e5;
test_statistics <- rep( 0, NMC ); # Vector to store our "fake" test statistics
# Now, NMC times, shuffle the data, recompute the test statistic, and record.
for(i in 1:NMC ) {
test_statistics[i] <- permute_and_compute( before, after );
}
# Now, let's make a histogram of those permuted test statistics.
hist( test_statistics )
hist( test_statistics )
abline( v=mean(treatment)-mean(control), lw=3, col='red' )
hist( test_statistics )
abline( v=mean(after)-mean(before), lw=3, col='red' )
# Code from class
permute_and_compute = function( before, after ) {
# Pool the data
pooled_data <- c( before, after );
# Randomly shuffle the data and assign it to control and treatment groups.
n_before <- length( before );
n_after <- length( after );
n_total <- n_before + n_after;
shuffled_data <- sample( pooled_data, size=n_total, replace=FALSE );
# Now, the first n_before of these data points are our new control group
# and the remaining elements are assigned to our treatment group.
shuffled_before <- shuffled_data[1:n_before];
shuffled_after <- shuffled_data[(n_before+1):n_total];
# Okay, last step: compute the difference in means of our two samples.
return( mean(shuffled_after)-mean(shuffled_before) );
}
# Monte Carlo
NMC <- 1e5;
test_statistics <- rep( 0, NMC ); # Vector to store our "fake" test statistics
# Now, NMC times, shuffle the data, recompute the test statistic, and record.
for(i in 1:NMC ) {
test_statistics[i] <- permute_and_compute( before, after );
}
# Now, let's make a histogram of those permuted test statistics.
hist( test_statistics )
hist( test_statistics )
abline( v=mean(after)-mean(before), lw=3, col='red' )
Tobsd <- mean(after) - mean(before); # Actually observed test statistic
# Monte Carlo estimate: how often in our simulation did the "fake" data
# have a difference in means greater than or equal to Tobsd?
sum(test_statistics >= Tobsd)/NMC;
Tobsd <- mean(after) - mean(before); # Actually observed test statistic
# Monte Carlo estimate: how often in our simulation did the "fake" data
# have a difference in means greater than or equal to Tobsd?
pvalue = sum(test_statistics >= Tobsd)/NMC;
pvalue
Tobsd
-Tobsd
Tobsd <- mean(after) - mean(before); # Actually observed test statistic.
# Monte Carlo estimate: how often in our simulation did the "fake" data
# have a difference in means greater than or equal to Tobsd?
pvalue = sum(test_statistics <= Tobsd | test_statistics >= (-Tobsd))/NMC;
pvalue
pbinom(112, size = 200, prob = 0.5)
pbinom(100, size = 200, prob = 0.5)
pbinom(99, size = 200, prob = 0.5)
pbinom(101, size = 200, prob = 0.5)
qbinom(0.50, size = 200, prob=0.5)
> qbinom(0.50, size = 200, prob=0.5)
qbinom(0.10, size = 416, prob=0.5)
1 - pbinom(46, 416, 0.1)
1 - pbinom(47, 416, 0.1)
flips1
split(flips1)
# Chunk 1: setup
knitr::opts_chunk$set(echo=T,eval=T,message=F,warning=F,fig.align='center')
# Chunk 2
years = c(2011:2022)
NMC = 1e5
definitelyWarmer = 0
for (i in 1:NMC){
randomYears = sample(years, 12, replace = FALSE)
if (sum(randomYears[5:12]) == sum(years[5:12])) {
definitelyWarmer = definitelyWarmer + 1
}
}
definitelyWarmer
# Chunk 3
prob = definitelyWarmer/NMC
prob
# Chunk 4
deck = rep(1:13,each=4)
deck
# Chunk 5
M = 1e5
diffCount = 0
for (i in 1:M) {
cards = sample(deck, 5, replace = FALSE)
if (length(unique(cards)) == 5) {
diffCount = diffCount + 1
}
}
diffCount
# Chunk 6
prob = diffCount / M
prob
# Chunk 7
noHigh = 0
hasHigh = function(vec) {
for (j in 1:length(vec)) {
if (vec[j] >= 10) {
return(TRUE)
}
}
return(FALSE)
}
for (i in 1:M) {
cards = sample(deck, 5, replace = FALSE)
if (hasHigh(cards) == FALSE) {
noHigh = noHigh + 1
}
}
noHigh
# Chunk 8
prob = noHigh / M
prob
# Chunk 9
twoPair = 0
hasTwoP = function(vec) {
vecTable = table(vec)
if (sum(vecTable == 2) == 2) {
return(TRUE)
} else {
return(FALSE)
}
}
for (i in 1:M) {
cards = sample(deck, 5, replace = FALSE)
if (hasTwoP(cards)) {
twoPair = twoPair + 1
}
}
flips1 = "HTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHT"
flips2 = "HHHTHTTTHHTHHTHHHTTTTHTHTHHTTHTHHHTHHTHTTTHTHHHTHTTTHTHTHHTHTHTTHTHHTHTHTTTHTHHHTHTHTTHTHTHHTHTHTHHHTHTTTHTHHTHTHTHHTTTHTHHTHHTTTTHTHTHHHTHTTHTHHTHTHTTHTHHTHTHHHTHHHTHTTTHTTHTTTHTHHHTHTHTTHTHHTHHTHTTT"
flips3 = "HHTHTHTTTHTHHHTHHTTTHTHHTHTTTHTHTHHTHTHTTHTHHHHHHTTTHTHTHHTHTTTHTHHTHTHTTTHTHHHTTHTTTHTHTHHHHTHTTHHTTTTTHTHHHTHTHTTTTTHHHTHHTHHTHHHTTTTHTHTHHHTHHTTTTTHTHHHTHTHTHTTTHTHHHTHTHTHTTHTHHTHTHTHTTTTHTHHHTHTH"
flips4 = "HTHHHHHHHTHTTHHTTHHHTHTHTTTHHTHHHTHHTTHTTTTTTTTTHTHHTTTTTHTHTHTHHTTHTTHTTTTTHHHTHTTTHTHTHHHTHTTTTHTHTHHTTHTHTTHHTHTHHHHTHTTHHTTHTTHTTHTHHHHHHTTTTTTHHHTTHTHHHHTTTHTTHHHTTHTHHTTTHHTHHTTTHTHHTHHHTHHTTHHH"
flips5 = "HHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTT"
flips6 = "TTHTTTHTTTTTTTHTHTHTHTTHTTHTHHTHHTTTHHTHTTTHTHHTHHHTHTTHHTHHTTHTHTTTTHTHTTTHHTTTTTTTTHTHHTTHTTTTTTHTHTHTHTTTHTTHHTTHTTTHHTTTHTTHTTTTHTTTTHHTTTHTHTHHHTTTTTTHTHHTTTTTTTTTTTTHHHTTTHHHTTTHTTTHTHTTHTTTTTHT"
# you can use the function below to split the above sequences in vectors of flips
split = function(str) strsplit(str, split="")[[1]]
split(flips1)
# install the runner package if necessary
if(!"runner" %in% rownames(installed.packages())) install.packages("runner")
# define function for tabulating consecutive pairs
tableOfPairs = function(vec){
return(table(runner::runner(vec,k=2,f=paste,collapse="")[-1]))
}
# test function for correct output
tableOfPairs(split(flips1))
length(flips1)
strlen(flips1)
strlength(flips1)
length(split(flips1))
length(split(flips2))
# Define a function to perform the chi-square test on the table of pairs
pairs_test <- function(sequence) {
pairs <- tableOfPairs(sequence)
expected_count <- sum(pairs)/2
expected_freqs <- c(expected_count, expected_count)
observed_freqs <- c(pairs["HT"], pairs["TH"])
chisq <- sum((observed_freqs - expected_freqs)^2 / expected_freqs)
p_value <- 1 - pchisq(chisq, df = length(expected_freqs) - 1)
return(p_value)
}
# Perform the test for each sequence
p_values <- sapply(list(flips1, flips2, flips3, flips4, flips5, flips6), pairs_test)
p_values
# Define a function to perform the chi-square test on the table of pairs
pairs_test <- function(sequence) {
pairs <- tableOfPairs(split(sequence))
expected_count <- sum(pairs)/2
expected_freqs <- c(expected_count, expected_count)
observed_freqs <- c(pairs["HT"], pairs["TH"])
chisq <- sum((observed_freqs - expected_freqs)^2 / expected_freqs)
p_value <- 1 - pchisq(chisq, df = length(expected_freqs) - 1)
return(p_value)
}
# Perform the test for each sequence
p_values <- sapply(list(flips1, flips2, flips3, flips4, flips5, flips6), pairs_test)
p_values
# install the runner package if necessary
if(!"runner" %in% rownames(installed.packages())) install.packages("runner")
# define function for tabulating consecutive pairs
tableOfPairs = function(vec){
return(table(runner::runner(vec,k=2,f=paste,collapse="")[-1]))
}
obs1 = tableOfPairs(split(flips1))
obs2 = tableOfPairs(split(flips2))
obs3 = tableOfPairs(split(flips3))
obs4 = tableOfPairs(split(flips4))
obs5 = tableOfPairs(split(flips5))
obs6 = tableOfPairs(split(flips6))
obs1
obs2
obs3
length(obs1)
length(obs2)
length(obs3)
length(obs4)
length(obs5)
length(obs6)
obs1
?chisq.test
chisq.test(obs6)
chisq.test(obs1)
chisq.test(obs2)
chisq.test(obs1, df = 3)
obs1
obs2
obs1 = cbind(obs1, HH, TT)
HH = 0
TT = 0
obs1 = cbind(obs1, HH, TT)
obs 1
obs1
typeof(obs2)
typeof(obs1)
class(obs2)
class(obs1)
obs1 = tableOfPairs(split(flips1))
obs1
obs1[1]
obs1[2]
typeof(obs1[1])
obs[1] = 3
obs1[1] = 3
obs1
obs1 = tableOfPairs(split(flips1))
obs1
obs1 = obs2
obs1
obs1[1] = 0
obs1[2] = 100
obs1[3] = 99
obs1[4] = 0
obs1
chisq.test(obs1)
chisq.test(obs2)
chisq.test(obs3)
chisq.test(obs4)
chisq.test(obs5)
chisq.test(obs6)
# get observed values for flips
obs1 = tableOfPairs(split(flips1))
obs2 = tableOfPairs(split(flips2))
obs3 = tableOfPairs(split(flips3))
obs4 = tableOfPairs(split(flips4))
obs5 = tableOfPairs(split(flips5))
obs6 = tableOfPairs(split(flips6))
# modify obs1 to include HH and TT columns
obs1 = obs2
obs1[1] = 0
obs1[2] = 100
obs1[3] = 99
obs1[4] = 0
# vector for expected values
expected = rep(199 * 0.25, 4)
pval1 = 1 - pchisq(sum((obs1 - expected)^2 / expected), df = 3)
pval2 = 1 - pchisq(sum((obs2 - expected)^2 / expected), df = 3)
pval3 = 1 - pchisq(sum((obs3 - expected)^2 / expected), df = 3)
pval4 = 1 - pchisq(sum((obs4 - expected)^2 / expected), df = 3)
pval5 = 1 - pchisq(sum((obs5 - expected)^2 / expected), df = 3)
pval6 = 1 - pchisq(sum((obs6 - expected)^2 / expected), df = 3)
pval1
pval2
obs1
obs2
obs3
obs4
obs5
obs6
longestRun = function(x,target = 'Y'){
max(0,with(rle(x), lengths[values==target]))
}
longestRun(split(obs1))
longestRun = function(x,target = 'Y'){
max(0,with(rle(x), lengths[values==target]))
}
longestRun(split(flips1))
longestRun = function(x,target = 'Y'){
max(0,with(rle(x), lengths[values==target]))
}
longestRun(split(flips5))
longestRun = function(x,target = 'H'){
max(0,with(rle(x), lengths[values==target]))
}
longestRun(split(flips5))
longestRun = function(x,target = 'H'){
max(0,with(rle(x), lengths[values==target]))
}
headStreak1 = longestRun(split(flips1))
headStreak2 = longestRun(split(flips2))
headStreak3 = longestRun(split(flips3))
headStreak4 = longestRun(split(flips4))
headStreak5 = longestRun(split(flips5))
headStreak6 = longestRun(split(flips6))
longestRun = function(x,target = 'H'){
max(0,with(rle(x), lengths[values==target]))
}
# generate vectors
vec1 = split(flips1)
vec2 = split(flips2)
vec3 = split(flips3)
vec4 = split(flips4)
vec5 = split(flips5)
vec6 = split(flips6)
headStreak1 = longestRun(vec1)
headStreak2 = longestRun(vec2)
headStreak3 = longestRun(vec3)
headStreak4 = longestRun(vec4)
headStreak5 = longestRun(vec5)
headStreak6 = longestRun(vec6)
# set number of reps to use
N = 10000
# create vector to save results in
mc.runs = rep(NA,N)
# for each rep, randomize sequence and find longest run of Y
for(i in 1:N){
mc.runs[i] = longestRun(sample(vec1))
}
mc.runs
hist(mc.runs)
headCount = 0
for(i in 1:N){
if (mc.runs[i] >= 10) {
headCount = headCount + 1
}
}
prob = headCount / N
prob
headCount = 0
for(i in 1:N){
if (mc.runs[i] < 2) {
headCount = headCount + 1
}
}
prob = headCount / N
prob
headCount = 0
for(i in 1:N){
if (mc.runs[i] < 2) {
headCount = headCount + 1
}
}
headCount
prob = headCount / N
prob
headCount = 0
for(i in 1:N){
if (mc.runs[i] < 4) {
headCount = headCount + 1
}
}
headCount
prob = headCount / N
prob
mc.runs
hist(mc.runs, breaks = 1)
hist(mc.runs, breaks = 10)
hist(mc.runs, breaks = 20)
hist(mc.runs, breaks = 50)
hist(mc.runs, breaks = 30)
hist(mc.runs, breaks = 10)
hist(mc.runs, breaks = 30)
hist(mc.runs, breaks = 20)
hist(mc.runs, breaks = 25)
hist(mc.runs, breaks = 23)
hist(mc.runs, breaks = 22)
hist(mc.runs, breaks = 21)
hist(mc.runs, breaks = 20)
headCount = 0
for(i in 1:N){
if (mc.runs[i] < 4) {
headCount = headCount + 1
}
}
headCount
prob = headCount / N
prob
headCount = 0
for(i in 1:N){
if (mc.runs[i] >= 7) {
headCount = headCount + 1
}
}
headCount
prob = headCount / N
prob
headCount = 0
for(i in 1:N){
if (mc.runs[i] >= 10) {
headCount = headCount + 1
}
}
headCount
prob = headCount / N
prob
