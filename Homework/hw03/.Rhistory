setwd("~/Desktop/School/Spring 2023/STAT 340/Homework/hw03")
# Chunk 1: setup
knitr::opts_chunk$set(echo=T,eval=T,message=F,warning=F,fig.align='center')
download.file('https://kdlevin-uwstat.github.io/STAT340-Fall2021/hw/03/mule_kicks.csv', destfile='mule_kicks.csv')
mule_kicks = read.csv('mule_kicks.csv', header=TRUE)
head(mule_kicks)
View(mule_kicks)
rgeom(5, 0.5)
rgeom(5, 0.3)
rgeom(5, 0.5)
rgeom(5, 0.5)
clear
setwd("~/Desktop/School/Spring 2023/STAT 340/Homework/hw03")
# Chunk 1: setup
knitr::opts_chunk$set(echo=T,eval=T,message=F,warning=F,fig.align='center')
# Chunk 2
download.file('https://kdlevin-uwstat.github.io/STAT340-Fall2021/hw/03/mule_kicks.csv', destfile='mule_kicks.csv')
mule_kicks = read.csv('mule_kicks.csv', header=TRUE)
head(mule_kicks)
lambdahat <- mean(mule_kicks%deaths)
lambdahat <- mean(mule_kicks$deaths)
View(mule_kicks)
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
replicates
rpois(5, 0.5)
rpois(5, 0.5)
rpois(5, 0.5)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambda_hat);
replicates[i] <- mean( fake_data );
}
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- mean( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
hist(mule_kicks$deaths, breaks = seq(-0.5, 12.5, by = 1), col = "skyblue", xlab = "Number of deaths by mule kick", main = "Histogram of deaths by mule kick in Prussian army")
abline(v = lambdahat, lty = "dashed", col = "red")
hist(mule_kicks$deaths)
hist(mule_kicks$deaths, xlab = "Deaths per year", title = "test")
hist(mule_kicks$deaths, xlab = "Deaths per year", main = "test")
hist(mule_kicks$deaths, xlab = "Deaths per year", main = "test")
hist(mule_kicks$deaths, xlab = "Deaths per year", main = "Histogram of Deaths per year")
plot(lambdahat, var(mule_kicks$deaths), xlab = "Sample mean", ylab = "Sample variance", main = "Sample mean versus sample variance")
abline(a = 0, b = 1, lty = "dashed", col = "red")
lambdahat
distVar = var(mule_kicks$deaths)
distVar
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- var( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- var( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- var( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- var( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- mean( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- mean( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- mean( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- mean( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- mean( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- mean( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- var( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- var( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- var( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- var( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
n = 280
Nrep <- 2000; # Number of repetitions (i.e., replicates)
replicates <- rep(NA,Nrep); # We will store replicates of lambdahat here.
for ( i in 1:Nrep) {
fake_data <- rpois(n=n, lambda=lambdahat);
replicates[i] <- var( fake_data );
}
# Now construct the confidence interval
CI <- quantile( replicates, probs=c(0.025, 0.975) );
cat(CI)
pbinom(x= 4, size = 5, lower.tail = FALSE)
pbinom(q = 4, size = 5, lower.tail = FALSE)
pbinom(q = 4, size = 5, prob = 0.82, lower.tail = FALSE)
pbinom(q = 4, size = 7, prob = 0.82, lower.tail = FALSE)
pbinom(q = 4, size = 8, prob = 0.82, lower.tail = FALSE)
pbinom(q = 4, size = 9, prob = 0.82, lower.tail = FALSE)
pbinom(q = 4, size = 10, prob = 0.82, lower.tail = FALSE)
hp <- mtcars$hp
mpg <- mtcars$mpg
plot(hp, mpg)
plot(hp, mpg, main = "Miles per gallon (mpg) VS Horsepower (hp)")
cov(hp,mpg)
Tobsd = cov(hp, mpg)
Tobsd
# Shuffling function from class
permute_and_compute <- function( hp_data, mpg_data ) {
pooled_data <- c( hp_data, mpg_data );
# Randomly shuffle the data and assign it to groups.
n_hp <- length( hp_data );
n_mpg <- length( mpg_data );
n_total <- n_hp + n_mpg;
shuffled_data <- sample( pooled_data, size=n_total, replace=FALSE );
shuffled_hp <- shuffled_data[1:n_hp];
shuffled_mpg <- shuffled_data[(n_hp+1):n_total];
return( cov(shuffled_mpg, shuffled_hp) );
}
NMC <- 1e4;
test_statistics <- rep( 0, NMC ); # Vector to store our "fake" test statistics
# Now, NMC times, shuffle the data, recompute the test statistic, and record.
for(i in 1:NMC ) {
test_statistics[i] <- permute_and_compute( hp, mpg );
}
hist( test_statistics )
abline( v=Tobsd, lw=3, col='red')
pvalue = sum(test_statistics >= Tobsd)/NMC
pvalue
head(test_statistics)
cor(hp,mpg)
Tobsd = cor(hp, mpg)
Tobsd
# Shuffling function from class
permute_and_compute <- function( hp_data, mpg_data ) {
pooled_data <- c( hp_data, mpg_data );
# Randomly shuffle the data and assign it to groups.
n_hp <- length( hp_data );
n_mpg <- length( mpg_data );
n_total <- n_hp + n_mpg;
shuffled_data <- sample( pooled_data, size=n_total, replace=FALSE );
shuffled_hp <- shuffled_data[1:n_hp];
shuffled_mpg <- shuffled_data[(n_hp+1):n_total];
return( cor(shuffled_mpg, shuffled_hp) );
}
NMC <- 1e4;
test_statistics <- rep( 0, NMC ); # Vector to store our "fake" test statistics
# Now, NMC times, shuffle the data, recompute the test statistic, and record.
for(i in 1:NMC ) {
test_statistics[i] <- permute_and_compute( hp, mpg );
}
hist( test_statistics )
abline( v=Tobsd, lw=3, col='red')
pvalue = sum(test_statistics >= Tobsd)/NMC
pvalue
Tobsd = cor(hp, mpg)
Tobsd
# Shuffling function from class
permute_and_compute <- function( hp_data, mpg_data ) {
pooled_data <- c( hp_data, mpg_data );
# Randomly shuffle the data and assign it to groups.
n_hp <- length( hp_data );
n_mpg <- length( mpg_data );
n_total <- n_hp + n_mpg;
shuffled_data <- sample( pooled_data, size=n_total, replace=FALSE );
shuffled_hp <- shuffled_data[1:n_hp];
shuffled_mpg <- shuffled_data[(n_hp+1):n_total];
return( cor(shuffled_mpg, shuffled_hp) );
}
NMC <- 1e4;
test_statistics <- rep( 0, NMC ); # Vector to store our "fake" test statistics
# Now, NMC times, shuffle the data, recompute the test statistic, and record.
for(i in 1:NMC ) {
test_statistics[i] <- permute_and_compute( hp, mpg );
}
hist( test_statistics )
abline( v=Tobsd, lw=3, col='red')
pvalue = sum(test_statistics >= abs(Tobsd))/NMC
pvalue
Tobsd = cor(hp, mpg)
Tobsd
# Shuffling function from class
permute_and_compute <- function( hp_data, mpg_data ) {
pooled_data <- c( hp_data, mpg_data );
# Randomly shuffle the data and assign it to groups.
n_hp <- length( hp_data );
n_mpg <- length( mpg_data );
n_total <- n_hp + n_mpg;
shuffled_data <- sample( pooled_data, size=n_total, replace=FALSE );
shuffled_hp <- shuffled_data[1:n_hp];
shuffled_mpg <- shuffled_data[(n_hp+1):n_total];
return( cor(shuffled_mpg, shuffled_hp) );
}
NMC <- 1e4;
test_statistics <- rep( 0, NMC ); # Vector to store our "fake" test statistics
# Now, NMC times, shuffle the data, recompute the test statistic, and record.
for(i in 1:NMC ) {
test_statistics[i] <- permute_and_compute( hp, mpg );
}
hist( test_statistics )
abline( v=Tobsd, lw=3, col='red')
pvalue = sum(test_statistics <= Tobsd | test_statistics >= abs(Tobsd))/NMC
pvalue
Tobsd = cor(hp, mpg)
Tobsd
# Shuffling function from class
permute_and_compute <- function( hp_data, mpg_data ) {
pooled_data <- c( hp_data, mpg_data );
# Randomly shuffle the data and assign it to groups.
n_hp <- length( hp_data );
n_mpg <- length( mpg_data );
n_total <- n_hp + n_mpg;
shuffled_data <- sample( pooled_data, size=n_total, replace=FALSE );
shuffled_hp <- shuffled_data[1:n_hp];
shuffled_mpg <- shuffled_data[(n_hp+1):n_total];
return( cor(shuffled_mpg, shuffled_hp) );
}
NMC <- 1e4;
test_statistics <- rep( 0, NMC ); # Vector to store our "fake" test statistics
# Now, NMC times, shuffle the data, recompute the test statistic, and record.
for(i in 1:NMC ) {
test_statistics[i] <- permute_and_compute( hp, mpg );
}
hist( test_statistics )
abline( v=Tobsd, lw=3, col='red')
pvalue = sum(test_statistics <= Tobsd | test_statistics >= abs(Tobsd))/NMC
pvalue
Tobsd = cor(hp, mpg)
Tobsd
# Shuffling function from class
permute_and_compute <- function( hp_data, mpg_data ) {
pooled_data <- c( hp_data, mpg_data );
# Randomly shuffle the data and assign it to groups.
n_hp <- length( hp_data );
n_mpg <- length( mpg_data );
n_total <- n_hp + n_mpg;
shuffled_data <- sample( pooled_data, size=n_total, replace=FALSE );
shuffled_hp <- shuffled_data[1:n_hp];
shuffled_mpg <- shuffled_data[(n_hp+1):n_total];
return( cor(shuffled_mpg, shuffled_hp) );
}
NMC <- 1e4;
test_statistics <- rep( 0, NMC ); # Vector to store our "fake" test statistics
# Now, NMC times, shuffle the data, recompute the test statistic, and record.
for(i in 1:NMC ) {
test_statistics[i] <- permute_and_compute( hp, mpg );
}
hist( test_statistics )
abline( v=Tobsd, lw=3, col='red')
pvalue = sum(test_statistics <= Tobsd | test_statistics >= abs(Tobsd))/NMC
pvalue
